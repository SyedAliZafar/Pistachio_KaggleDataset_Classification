{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89dcbcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d2fbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliz\\Anaconda3\\envs\\Time_Series\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "C:\\Users\\aliz\\Anaconda3\\envs\\Time_Series\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import splitfolders\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2928f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2148 files [00:02, 981.03 files/s] \n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "Dataset_dir = r'D:\\Mubassira\\KaggleProject\\Pistacho\\Pistachio_Image_Dataset\\Pistachio_Image_Dataset'\n",
    "Dataset_dir =pathlib.Path(Dataset_dir)\n",
    "\n",
    "splitfolders.ratio(Dataset_dir, output=\"Pistachio_dataset\", seed=101, ratio=(.7, .2, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64bb1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Mubassira/KaggleProject/Pistacho/Pistachio_Image_Dataset/Pistachio_Image_Dataset')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_dir \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f0dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29281c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d207d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (height=600, width=600, channels=3)\n"
     ]
    }
   ],
   "source": [
    "# We can check image shape using this code\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('../Pistachio_Image_Dataset/Pistachio_dataset/train/Kirmizi_Pistachio/kirmizi (12).jpg')\n",
    "\n",
    "# Check the shape of the image\n",
    "height, width, channels = image.shape\n",
    "# Dataset comprises of images of shape: (600,600,3)\n",
    "# Print the image shape\n",
    "print(f\"Image shape: (height={height}, width={width}, channels={channels})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf58393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f5916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"../Pistachio_Image_Dataset/Pistachio_dataset/train\"\n",
    "test_dir = \"../Pistachio_Image_Dataset/Pistachio_dataset/test\"\n",
    "val_dir = \"../Pistachio_Image_Dataset/Pistachio_dataset/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fdd8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Display the image in a window with the name \"image\"\n",
    "cv2.imshow(\"image\", image)\n",
    "# Wait for a key event and close the window when a key is pressed\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780f852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cedf794e",
   "metadata": {},
   "source": [
    "##\n",
    "Data augmentation is a technique used to artificially increase the diversity of your training dataset by applying various transformations to the existing images. This helps improve the generalization and robustness of a machine learning model. Let's go through each parameter in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44b8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "image_height, image_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation Data Generator (No Data Augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023e7b",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data:\n",
    "* Load your dataset and preprocess it. \n",
    "* If you are working with image data, you might use the ImageDataGenerator for data augmentation and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5125fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1503 images belonging to 2 classes.\n",
      "Found 429 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Data Generator\n",
    "# Training Data Generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']  # Specify class labels\n",
    ")\n",
    "\n",
    "# Validation Data Generator\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']  # Specify class labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b23d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We have to created image generator for the validation dataset\n",
    "\n",
    "\n",
    "# For testing\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    )\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle = True,\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']  # Specify class labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2397e531",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## After the dataset are seperated,we need to make the label file according to each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd768478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images:  1503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "Total_TrainImages = glob.glob('../Pistachio_Image_Dataset/Pistachio_dataset/train/*/*.jpg')\n",
    "print(\"Total number of training images: \", len(Total_TrainImages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8e7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels\n",
    "images, labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326441a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape - Images: (32, 224, 224, 3)\n",
      "Batch shape - Labels: (32, 2)\n",
      "Image 1: Label - [1. 0.]\n",
      "Image 2: Label - [0. 1.]\n",
      "Image 3: Label - [1. 0.]\n",
      "Image 4: Label - [1. 0.]\n",
      "Image 5: Label - [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of images and labels\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Print the shape of the batch\n",
    "print(\"Batch shape - Images:\", images.shape)\n",
    "print(\"Batch shape - Labels:\", labels.shape)\n",
    "\n",
    "# Print the labels for the first few images\n",
    "for i in range(min(batch_size, 5)):  # Print labels for the first 5 images\n",
    "    print(f\"Image {i+1}: Label - {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3b1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Specify the number of batches to visualize (adjust as needed)\n",
    "num_batches = 5\n",
    "\n",
    "# Iterate through the generator and accumulate file paths and labels\n",
    "for _ in range(num_batches):\n",
    "    batch_images, batch_labels = next(train_generator)\n",
    "    batch_file_paths = train_generator.filepaths  # Get the file paths from the generator\n",
    "\n",
    "    file_paths.extend(batch_file_paths)\n",
    "    labels.extend(batch_labels)\n",
    "\n",
    "# Convert lists to a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'File_Path': file_paths[:len(labels)],  # Ensure both lists have the same length\n",
    "    'Label': np.argmax(labels, axis=1)  # Convert one-hot encoded labels to class indices\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0e16090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           File_Path  Label\n",
       "0  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "1  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      1\n",
       "2  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "3  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "4  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "913054b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>../Pistachio_Image_Dataset/Pistachio_dataset/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File_Path  Label\n",
       "0    ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "1    ../Pistachio_Image_Dataset/Pistachio_dataset/t...      1\n",
       "2    ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "3    ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "4    ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "..                                                 ...    ...\n",
       "155  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "156  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "157  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "158  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      0\n",
       "159  ../Pistachio_Image_Dataset/Pistachio_dataset/t...      1\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514075df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_height, image_width, 3))\n",
    "\n",
    "# Freeze the convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top of VGG16\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming 2 classes: Kirmizi_Pistachio and Siirt_Pistachio\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators with data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 46s 971ms/step - loss: 0.6959 - accuracy: 0.5855 - val_loss: 0.5323 - val_accuracy: 0.7669\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 44s 925ms/step - loss: 0.6279 - accuracy: 0.6480 - val_loss: 0.5319 - val_accuracy: 0.7832\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 45s 949ms/step - loss: 0.6201 - accuracy: 0.6587 - val_loss: 0.5388 - val_accuracy: 0.6876\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 46s 986ms/step - loss: 0.6095 - accuracy: 0.6680 - val_loss: 0.5426 - val_accuracy: 0.8019\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 45s 958ms/step - loss: 0.5919 - accuracy: 0.6860 - val_loss: 0.4994 - val_accuracy: 0.7576\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 46s 971ms/step - loss: 0.5808 - accuracy: 0.6886 - val_loss: 0.4863 - val_accuracy: 0.7925\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 46s 973ms/step - loss: 0.6073 - accuracy: 0.6534 - val_loss: 0.5224 - val_accuracy: 0.7879\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 45s 947ms/step - loss: 0.5994 - accuracy: 0.6640 - val_loss: 0.4819 - val_accuracy: 0.8112\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 47s 999ms/step - loss: 0.5872 - accuracy: 0.6953 - val_loss: 0.5116 - val_accuracy: 0.7669\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.6840"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # You can adjust this based on your needs\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f71ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
