{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dcbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3c461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347b2777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d2fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import splitfolders\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2928f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2148 files [00:02, 787.19 files/s]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import splitfolders\n",
    "\n",
    "Dataset_dir = r'..\\..\\Dataset\\Pistachio_Image_Dataset'\n",
    "\n",
    "Dataset_dir = pathlib.Path(Dataset_dir)\n",
    "\n",
    "# Ensure that splitfolders is imported\n",
    "# If not, you can import it using:\n",
    "# from splitfolders import split\n",
    "\n",
    "# Use the split function to create the output folders\n",
    "splitfolders.ratio(Dataset_dir, output=\"../../Dataset/Pistachio_Dataset\", seed=101, ratio=(.7, .2, .1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29281c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d207d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (height=600, width=600, channels=3)\n"
     ]
    }
   ],
   "source": [
    "# We can check image shape using this code\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('../../Dataset/Pistachio_Dataset/train/Kirmizi_Pistachio/kirmizi (10).jpg')\n",
    "\n",
    "# Check the shape of the image\n",
    "height, width, channels = image.shape\n",
    "# Dataset comprises of images of shape: (600,600,3)\n",
    "# Print the image shape\n",
    "print(f\"Image shape: (height={height}, width={width}, channels={channels})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf58393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f5916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"../../Dataset//Pistachio_dataset/train\"\n",
    "test_dir = \"../../Dataset//Pistachio_dataset/test\"\n",
    "val_dir = \"../../Dataset//Pistachio_dataset/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf794e",
   "metadata": {},
   "source": [
    "##\n",
    "Data augmentation is a technique used to artificially increase the diversity of your training dataset by applying various transformations to the existing images. This helps improve the generalization and robustness of a machine learning model. Let's go through each parameter in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44b8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "image_height, image_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation Data Generator (No Data Augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023e7b",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data:\n",
    "* Load your dataset and preprocess it. \n",
    "* If you are working with image data, you might use the ImageDataGenerator for data augmentation and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5125fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1503 images belonging to 2 classes.\n",
      "Found 429 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Data Generator\n",
    "# Training Data Generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']  # Specify class labels\n",
    ")\n",
    "\n",
    "# Validation Data Generator\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']  # Specify class labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b23d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We have to created image generator for the validation dataset\n",
    "\n",
    "\n",
    "# For testing\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    )\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle = True,\n",
    "    classes=['Kirmizi_Pistachio', 'Siirt_Pistachio']  # Specify class labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd768478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images:  1503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "Total_TrainImages = glob.glob('../../Dataset/Pistachio_dataset/train/*/*.jpg')\n",
    "print(\"Total number of training images: \", len(Total_TrainImages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "514075df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_height, image_width, 3))\n",
    "\n",
    "# Freeze the convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top of VGG16\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())  # Use Global Average Pooling instead of Flatten\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming 2 classes: Kirmizi_Pistachio and Siirt_Pistachio\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "47/47 [==============================] - 73s 2s/step - loss: 6.4522 - accuracy: 0.4859 - val_loss: 5.7727 - val_accuracy: 0.5734\n",
      "Epoch 2/60\n",
      "47/47 [==============================] - 74s 2s/step - loss: 6.2298 - accuracy: 0.5197 - val_loss: 5.7267 - val_accuracy: 0.5734\n",
      "Epoch 3/60\n",
      "47/47 [==============================] - 74s 2s/step - loss: 6.2086 - accuracy: 0.5301 - val_loss: 5.6778 - val_accuracy: 0.5781\n",
      "Epoch 4/60\n",
      "47/47 [==============================] - 75s 2s/step - loss: 6.1422 - accuracy: 0.5239 - val_loss: 5.6294 - val_accuracy: 0.5944\n",
      "Epoch 5/60\n",
      "47/47 [==============================] - 77s 2s/step - loss: 6.0586 - accuracy: 0.5354 - val_loss: 5.5828 - val_accuracy: 0.6783\n",
      "Epoch 6/60\n",
      "47/47 [==============================] - 79s 2s/step - loss: 5.9879 - accuracy: 0.5595 - val_loss: 5.5354 - val_accuracy: 0.7133\n",
      "Epoch 7/60\n",
      "47/47 [==============================] - 78s 2s/step - loss: 5.9213 - accuracy: 0.5758 - val_loss: 5.4886 - val_accuracy: 0.7086\n",
      "Epoch 8/60\n",
      "47/47 [==============================] - 78s 2s/step - loss: 5.9658 - accuracy: 0.5590 - val_loss: 5.4365 - val_accuracy: 0.7040\n",
      "Epoch 9/60\n",
      "19/47 [===========>..................] - ETA: 35s - loss: 5.8337 - accuracy: 0.5974"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "num_epochs= 60\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=3,           # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# Assuming you have already trained the model and stored the history\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]  # Include EarlyStopping callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f71ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already trained the model and stored the history\n",
    "#history = model.fit(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "\n",
    "# Plot training and validation loss values\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6809e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
